{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Mining Portfolio.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMxSM1s7ZUTc"
      },
      "source": [
        "---\n",
        "\n",
        "# **Product Backorders**\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction\n",
        "A **product backorder** is a customer order that has not been fulfilled. Product backorder may be the result of strong sales performance (e.g. the product is in such high demand that production cannot keep up with sales). However, backorders can upset consumers, lead to canceled orders and decreased customer loyalty. Companies want to avoid backorders, but also avoid overstocking every product (leading to higher inventory costs). Hence, this project aims to develop a product that can predict if a product will go on backorder not.\n",
        "\n",
        "---\n",
        "\n",
        "## Problem Statement\n",
        "1.   What are the variables that lead to backorder?\n",
        "2.   What are the relationship between the varialbes?\n",
        "\n",
        "---\n",
        "\n",
        "## Hypothesis\n",
        "National inventory and sales performance are directly correlated with backorder.\n",
        "\n",
        "---\n",
        "\n",
        "## Objective\n",
        "1.   To identify the relationship between the attributes\n",
        "2.   To identify which attributes correlates most to backorder\n",
        "3.   To predict backorder by selecting relevant attributes\n",
        "\n",
        "---\n",
        "\n",
        "## Dataset\n",
        "From the [Backorders Wiki Page](https://github.com/AasthaMadan/Product-Backorders/wiki/Product-back-orders-prediction), we can find the information about the dataset\n",
        "\n",
        "*   sku – Random ID for the product\n",
        "*   national_inv – Current inventory level for the part\n",
        "*   lead_time – Transit time for product (if available)\n",
        "*   in_transit_qty – Amount of product in transit from source\n",
        "*   forecast_3_month – Forecast sales for the next 3 months\n",
        "*   forecast_6_month – Forecast sales for the next 6 months\n",
        "*   forecast_9_month – Forecast sales for the next 9 months\n",
        "*   sales_1_month – Sales quantity for the prior 1 month time period\n",
        "*   sales_3_month – Sales quantity for the prior 3 month time period\n",
        "*   sales_6_month – Sales quantity for the prior 6 month time period\n",
        "*   sales_9_month – Sales quantity for the prior 9 month time period\n",
        "*   min_bank – Minimum recommend amount to stock\n",
        "*   potential_issue – Source issue for part identified\n",
        "*   pieces_past_due – Parts overdue from source\n",
        "*   perf_6_month_avg – Source performance for prior 6 month period\n",
        "*   perf_12_month_avg – Source performance for prior 12 month period\n",
        "*   local_bo_qty – Amount of stock orders overdue\n",
        "*   deck_risk – Part risk flag\n",
        "*   oe_constraint – Part risk flag\n",
        "*   ppap_risk – Part risk flag\n",
        "*   stop_auto_buy – Part risk flag\n",
        "*   rev_stop – Part risk flag\n",
        "*   went_on_backorder – Product actually went on backorder.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sUjm2hDZm4a"
      },
      "source": [
        "# **Exploratory Data Analysis**\r\n",
        "\r\n",
        "Exploratory data analysis is the inital investigation of data so as to discover patterns, spot anomalies, and test hypothesis with the help of statistics.\r\n",
        "\r\n",
        "To do this, we will first import our datasets and merge them using the pandas library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fUlMS5cZ774",
        "outputId": "d00352ae-5aa6-4a81-c39e-2c63558cb0e6"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# Load train and test data\r\n",
        "train_df = pd.read_csv(\"drive/MyDrive/data_mining_portfolio/Kaggle_Training_Dataset_v2.csv\")\r\n",
        "test_df = pd.read_csv(\"drive/MyDrive/data_mining_portfolio/Kaggle_Test_Dataset_v2.csv\")\r\n",
        "\r\n",
        "# Merge both the datasets\r\n",
        "merged_df = pd.concat([train_df, test_df])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBAIPQT5apCq"
      },
      "source": [
        "Next, we can look at some properties of the dataset such as shape, data types, and part of the actual data itself. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG7k9-cbOl63",
        "outputId": "efe9cf26-6196-43f8-9ae8-520b62ca9e84"
      },
      "source": [
        "# Size of dataset\r\n",
        "print(\"Shape:\\n\", merged_df.shape)\r\n",
        "\r\n",
        "# Look at the data types\r\n",
        "print(\"\\nDatatypes:\\n\", merged_df.dtypes)\r\n",
        "\r\n",
        "# An initial look at the 1st 5 rows \r\n",
        "print(\"\\nFirst 5:\\n\", merged_df.head())\r\n",
        "\r\n",
        "# The last 5 rows\r\n",
        "print(\"\\nLast5:\\n\", merged_df.tail())\r\n",
        "\r\n",
        "# Count number of null values for each variable\r\n",
        "print(\"\\nNulls:\\n\", merged_df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:\n",
            " (1929937, 23)\n",
            "\n",
            "Datatypes:\n",
            " sku                   object\n",
            "national_inv         float64\n",
            "lead_time            float64\n",
            "in_transit_qty       float64\n",
            "forecast_3_month     float64\n",
            "forecast_6_month     float64\n",
            "forecast_9_month     float64\n",
            "sales_1_month        float64\n",
            "sales_3_month        float64\n",
            "sales_6_month        float64\n",
            "sales_9_month        float64\n",
            "min_bank             float64\n",
            "potential_issue       object\n",
            "pieces_past_due      float64\n",
            "perf_6_month_avg     float64\n",
            "perf_12_month_avg    float64\n",
            "local_bo_qty         float64\n",
            "deck_risk             object\n",
            "oe_constraint         object\n",
            "ppap_risk             object\n",
            "stop_auto_buy         object\n",
            "rev_stop              object\n",
            "went_on_backorder     object\n",
            "dtype: object\n",
            "\n",
            "First 5:\n",
            "        sku  national_inv  lead_time  ...  stop_auto_buy  rev_stop  went_on_backorder\n",
            "0  1026827           0.0        NaN  ...            Yes        No                 No\n",
            "1  1043384           2.0        9.0  ...            Yes        No                 No\n",
            "2  1043696           2.0        NaN  ...            Yes        No                 No\n",
            "3  1043852           7.0        8.0  ...            Yes        No                 No\n",
            "4  1044048           8.0        NaN  ...            Yes        No                 No\n",
            "\n",
            "[5 rows x 23 columns]\n",
            "\n",
            "Last5:\n",
            "                   sku  national_inv  ...  rev_stop  went_on_backorder\n",
            "242071        3526988          13.0  ...        No                 No\n",
            "242072        3526989          13.0  ...        No                 No\n",
            "242073        3526990          10.0  ...        No                 No\n",
            "242074        3526991        2913.0  ...        No                 No\n",
            "242075  (242075 rows)           NaN  ...       NaN                NaN\n",
            "\n",
            "[5 rows x 23 columns]\n",
            "\n",
            "Nulls:\n",
            " sku                       0\n",
            "national_inv              2\n",
            "lead_time            115619\n",
            "in_transit_qty            2\n",
            "forecast_3_month          2\n",
            "forecast_6_month          2\n",
            "forecast_9_month          2\n",
            "sales_1_month             2\n",
            "sales_3_month             2\n",
            "sales_6_month             2\n",
            "sales_9_month             2\n",
            "min_bank                  2\n",
            "potential_issue           2\n",
            "pieces_past_due           2\n",
            "perf_6_month_avg          2\n",
            "perf_12_month_avg         2\n",
            "local_bo_qty              2\n",
            "deck_risk                 2\n",
            "oe_constraint             2\n",
            "ppap_risk                 2\n",
            "stop_auto_buy             2\n",
            "rev_stop                  2\n",
            "went_on_backorder         2\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiB63iiQV0pV"
      },
      "source": [
        "We find out that:\r\n",
        "\r\n",
        "*   We can see there's almost 2 million records with 23 different attributes,\r\n",
        "*   15 of these attributes are numerical\r\n",
        "*   8 of these attributes are non-numerical\r\n",
        "*   lead_time has 115619 null values\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "We now aggregate the dataset, first a summary of the overall dataset, then a summary with separating the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPwThjgROmLe",
        "outputId": "7a2b7a5f-3de6-444b-ed75-a839937dea56"
      },
      "source": [
        "# Select numerical parameters\r\n",
        "num_params = ['national_inv',\r\n",
        "           'lead_time',\r\n",
        "           'in_transit_qty',\r\n",
        "           'forecast_3_month',\r\n",
        "           'forecast_6_month',\r\n",
        "           'forecast_9_month',\r\n",
        "           'sales_1_month',\r\n",
        "           'sales_3_month',\r\n",
        "           'sales_6_month',\r\n",
        "           'sales_9_month',\r\n",
        "           'min_bank',\r\n",
        "           'pieces_past_due',\r\n",
        "           'perf_6_month_avg',\r\n",
        "           'perf_12_month_avg',\r\n",
        "           'local_bo_qty']\r\n",
        "\r\n",
        "# Describe data\r\n",
        "print(\"\\nSummary:\\n\", merged_df[num_params].describe().transpose())\r\n",
        "\r\n",
        "# Pivot backorder\r\n",
        "print(\"\\nBackorder:\\n\", merged_df.pivot_table(values=num_params,index=['went_on_backorder']).transpose())\r\n",
        "\r\n",
        "# Class proportion for target variable\r\n",
        "print(\"\\nProportion of Backorder before SMOTE:\\n\", merged_df['went_on_backorder'].value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Summary:\n",
            "                        count        mean  ...    75%         max\n",
            "national_inv       1929935.0  496.568259  ...  80.00  12334404.0\n",
            "lead_time          1814318.0    7.878627  ...   9.00        52.0\n",
            "in_transit_qty     1929935.0   43.064397  ...   0.00    489408.0\n",
            "forecast_3_month   1929935.0  178.539864  ...   4.00   1510592.0\n",
            "forecast_6_month   1929935.0  345.465893  ...  12.00   2461360.0\n",
            "forecast_9_month   1929935.0  506.606748  ...  20.00   3777304.0\n",
            "sales_1_month      1929935.0   55.368164  ...   4.00    741774.0\n",
            "sales_3_month      1929935.0  174.663858  ...  15.00   1105478.0\n",
            "sales_6_month      1929935.0  341.565349  ...  31.00   2146625.0\n",
            "sales_9_month      1929935.0  523.577094  ...  47.00   3205172.0\n",
            "min_bank           1929935.0   52.776366  ...   3.00    313319.0\n",
            "pieces_past_due    1929935.0    2.016193  ...   0.00    146496.0\n",
            "perf_6_month_avg   1929935.0   -6.899870  ...   0.96         1.0\n",
            "perf_12_month_avg  1929935.0   -6.462343  ...   0.95         1.0\n",
            "local_bo_qty       1929935.0    0.653704  ...   0.00     12530.0\n",
            "\n",
            "[15 rows x 8 columns]\n",
            "\n",
            "Backorder:\n",
            " went_on_backorder          No         Yes\n",
            "forecast_3_month   178.566740  174.856734\n",
            "forecast_6_month   345.974100  275.821257\n",
            "forecast_9_month   507.636728  365.458479\n",
            "in_transit_qty      43.344159    4.725842\n",
            "lead_time            7.890117    6.354233\n",
            "local_bo_qty         0.626744    4.348258\n",
            "min_bank            52.962026   27.333524\n",
            "national_inv       500.036607   21.266361\n",
            "perf_12_month_avg   -6.488200   -2.918946\n",
            "perf_6_month_avg    -6.926540   -3.245012\n",
            "pieces_past_due      2.003972    3.691009\n",
            "sales_1_month       55.556432   29.567914\n",
            "sales_3_month      175.322597   84.390315\n",
            "sales_6_month      342.979619  147.753952\n",
            "sales_9_month      525.812742  217.204134\n",
            "\n",
            "Proportion of Backorder before SMOTE:\n",
            " No     0.992756\n",
            "Yes    0.007244\n",
            "Name: went_on_backorder, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8TmySTDBDPn"
      },
      "source": [
        "We find that overall:\r\n",
        "*   The mean inventory of products is about 500\r\n",
        "*   The mean product in transit is 43\r\n",
        "*   The mean sales per month is 55\r\n",
        "\r\n",
        "When separated by class:\r\n",
        "*   The product that did not go on backorders, have high inventory, but also higher sales and quantity in transit.\r\n",
        "*   The product that go on backorders, have low inventory, but also lower sales and quantity in transit.\r\n",
        "*   **For products that go on backorder, the sales is higher than the inventory, whereas for products that do not go on backorder, the sales is lower than the inventory.**\r\n",
        "\r\n",
        "This confirms our hypothesis, in that national inventory and sales performance are directly correlated with backorder.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now we can construct a correlation matrix to see the correlation between each attributes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "djHKat54BCkf",
        "outputId": "339daa57-10e0-4c5f-d7a0-ae2f96b0eafd"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Correlation Matrix Plot of all variables\r\n",
        "varnames=list(merged_df)[1:]    \r\n",
        "correlations = merged_df[varnames].corr()\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.add_subplot(111)\r\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1)\r\n",
        "fig.colorbar(cax)\r\n",
        "ticks = np.arange(0,23,1)\r\n",
        "ax.set_xticks(ticks)\r\n",
        "ax.set_yticks(ticks)\r\n",
        "ax.set_xticklabels(varnames,rotation=90)\r\n",
        "ax.set_yticklabels(varnames)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTd29pvsTtNw"
      },
      "source": [
        "We can see that:\r\n",
        "\r\n",
        "*   Sales and forecast variables are highly correlated.\r\n",
        "\r\n",
        "This means that, when doing our prediction, we don't have to use every attributes that correlate highly with each other. Using fewer attributes may speed up training time.\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR6JfVlEElDc"
      },
      "source": [
        "## Tableau EDA\r\n",
        "\r\n",
        "We can now perform more complex data analysis on Tableau. The first chart we will look at is **Real sales vs forecast**:\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1ssA2Qwh7XkgwkKPI5bjAfJAAkbpfSH0M)\r\n",
        "\r\n",
        "We see that the prediction in the original dataset correlates highly with the real sales. We can investigate further by looking at the \"yes\" and \"no\" backorder products separately.\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1YSdv74N5oC-8aDxpzRJ1AcJjlBlCY56a)\r\n",
        "\r\n",
        "For the \"no\" backorder products, the forecasted sales and the actual sales are the same. But for the \"yes\" backorder products, there is a disparity between the forecasted sales and the actual sales. \r\n",
        "\r\n",
        "**The actual sales are higher than the forecasted sales for backorder products.**\r\n",
        "\r\n",
        "---\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46ko9s7hZntx"
      },
      "source": [
        "# **Data Pre-processing**\r\n",
        "Data pre-processing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often inconsistent and incomplete, and we need to transform it into a format that our machine learning models can understand.\r\n",
        "\r\n",
        "First of all, we need to get rid of the null value sas there are many null values in the dataset. We also remove the 'SKU' column as it is the ID of the product and are not meaningful in any way.\r\n",
        "\r\n",
        "After that, we can compare the proportion of \"Yes\" and \"No\" backorder products:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbSYsVM4Z9Nw",
        "outputId": "b6b8bd83-9433-47bf-bb05-0dc7cf788be9"
      },
      "source": [
        "from sklearn.preprocessing import normalize\r\n",
        "from imblearn.over_sampling import SMOTE\r\n",
        "\r\n",
        "# Replace NaN values in lead_time\r\n",
        "merged_df.lead_time = merged_df.lead_time.fillna(merged_df.lead_time.median())\r\n",
        "\r\n",
        "# Change the -99 placeholder to NA for perf_6_month_avg and perf_12_month_avg\r\n",
        "merged_df['perf_6_month_avg'] = merged_df['perf_6_month_avg'].replace(-99, np.NaN)\r\n",
        "merged_df['perf_12_month_avg'] = merged_df['perf_12_month_avg'].replace(-99, np.NaN)\r\n",
        "\r\n",
        "# Drop rows with null values \r\n",
        "merged_df = merged_df.dropna()\r\n",
        "\r\n",
        "# Remove the sku column\r\n",
        "merged_df = merged_df.drop([\"sku\"], axis=1)\r\n",
        "\r\n",
        "# Class proportion for target variable\r\n",
        "print(\"\\nProportion of Backorder before SMOTE:\\n\", merged_df['went_on_backorder'].value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Proportion of Backorder before SMOTE:\n",
            " No     0.992462\n",
            "Yes    0.007538\n",
            "Name: went_on_backorder, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frG5185Lav1I"
      },
      "source": [
        "And find out that 98.13% of products are \"Yes\" backorder and only 1.87% are \"No\" backorder.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Next, we want to transform the 'Yes' and 'No' values to '1' and '0', as some models are not able to work with non-numerical values. Also, we want to remove the records where forecast and sales are 0, because these products do not contribute to our prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaOmA5prOx3e"
      },
      "source": [
        "# Convert from non-numerical to numerical\r\n",
        "cat_params = ['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk',\r\n",
        "               'stop_auto_buy', 'rev_stop', 'went_on_backorder']\r\n",
        "\r\n",
        "for param in cat_params:\r\n",
        "  merged_df[param] = (merged_df[param] == 'Yes').astype(int)\r\n",
        "\r\n",
        "# Remove records where forecast and sales are 0 \r\n",
        "attributes = ['forecast_3_month', 'forecast_6_month', 'forecast_9_month',\r\n",
        "              'sales_1_month', 'sales_3_month', 'sales_6_month', 'sales_9_month']\r\n",
        "              \r\n",
        "for attr in attributes:\r\n",
        "  merged_df = merged_df.drop(merged_df[merged_df[attr] == 0].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT1GEuP_axOP"
      },
      "source": [
        "As the data is still vastly unbalanced, we need to balance it somehow. We can do this by applying the SMOTE technique. After that, we can save it to a csv file for future use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsJVA1SuV_RW",
        "outputId": "705b7f83-ab62-4ecd-b746-a8c4b3c62886"
      },
      "source": [
        "# SMOTE teachnique to balance dataset\r\n",
        "X = merged_df.drop(['went_on_backorder'], axis = 1)\r\n",
        "y = merged_df['went_on_backorder']\r\n",
        "oversample = SMOTE()\r\n",
        "X, y = oversample.fit_resample(X, y)\r\n",
        "df = pd.concat([pd.DataFrame(X), pd.DataFrame(y)], axis=1)\r\n",
        "\r\n",
        "# Rename labels in final dataset\r\n",
        "labels = merged_df.columns\r\n",
        "df.columns = labels\r\n",
        "\r\n",
        "# Save to csv\r\n",
        "df.to_csv(r'data.csv')\r\n",
        "\r\n",
        "# Class proportion before SMOTE\r\n",
        "print(\"\\nProportion of Backorder before SMOTE:\\n\", merged_df['went_on_backorder'].value_counts(normalize=True))\r\n",
        "\r\n",
        "# Class proportion after SMOTE\r\n",
        "print(\"\\nProportion of Backorder after SMOTE:'n\", df['went_on_backorder'].value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Proportion of Backorder before SMOTE:\n",
            " 0    0.981289\n",
            "1    0.018711\n",
            "Name: went_on_backorder, dtype: float64\n",
            "\n",
            "Proportion of Backorder after SMOTE:'n 1    0.5\n",
            "0    0.5\n",
            "Name: went_on_backorder, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bypNj39ZuOS"
      },
      "source": [
        "---\r\n",
        "# **Descriptive Data Mining**\r\n",
        "\r\n",
        "Descriptive data mining is applying data mining techniques to determine the similarities in the data and to find existing patterns.\r\n",
        "\r\n",
        "We will apply 2 descriptive data mining techniques here:\r\n",
        "1.   A Priori Association Rules\r\n",
        "2.   K-Means Clustering\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq4RJjGFGZ7s"
      },
      "source": [
        "## Association Rules\r\n",
        "Association Rules calculate how frequent the items appear together\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "### RapidMiner\r\n",
        "We first run this on RapidMiner. The data is first discretized and transformed to Binomial before we process it. It should be noted that we are running FPGrowth in RapidMiner because it does not have A Priori. We use A Priori Association Rules on Colab because FPgrowth is unavailable here. However, they are very similar algorithms. The figure below shows the operators used in RapidMiner:\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1TzFOGjPmjdhpcyIp5m4Wu2CZVgmtbQiy)\r\n",
        "\r\n",
        "And the two figures below shows the output:\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1ZCb2ceXNirSBVqiW_AqT4beIq0WpxT3w)\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1_EZf5p8_SjrZYzHy3qVvoLeX3y4J2_mM)\r\n",
        "\r\n",
        "We can conclude from the results that, when\r\n",
        "*   oe_constraint\r\n",
        "*   potential_issue\r\n",
        "*   desk_risk\r\n",
        "\r\n",
        "is **False**, then rev_stop will most probably also be **False**\r\n",
        "\r\n",
        "Next, we export the data that we have processed here into a CSV that we can use on Colab.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "We can now use the data that is exported and run A Priori Association Rules on Colab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us37duhHaFvP",
        "outputId": "f759ccd7-b0f6-45aa-c22a-218927b23a4b"
      },
      "source": [
        "!pip install -q mlxtend\r\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "# Read data\r\n",
        "disc_df = pd.read_csv(\"drive/MyDrive/data_mining_portfolio/discretized.csv\")\r\n",
        "\r\n",
        "# Analyze frequent itemsets and write to csv\r\n",
        "ap = apriori(disc_df, min_support=0.95, use_colnames=True)\r\n",
        "print(\"\\nFrequent Itemsets:\\n\", ap)\r\n",
        "ap.to_csv('itemsets.csv')\r\n",
        "\r\n",
        "# Create association rules and write to csv\r\n",
        "rules = association_rules(ap, metric=\"confidence\", min_threshold=0.8)\r\n",
        "print(\"\\nAssociation Rules:\\n\", rules)\r\n",
        "rules.to_csv('rules.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Frequent Itemsets:\n",
            "      support                                           itemsets\n",
            "0   0.998698            (potential_issue = range1 [-? - 0.500])\n",
            "1   0.950488                  (deck_risk = range1 [-? - 0.500])\n",
            "2   0.999755              (oe_constraint = range1 [-? - 0.500])\n",
            "3   0.960804                   (stop_auto_buy = range2 [0 - ?])\n",
            "4   1.000000                       (rev_stop = range1 [-? - 0])\n",
            "5   0.998453  (oe_constraint = range1 [-? - 0.500], potentia...\n",
            "6   0.959502  (stop_auto_buy = range2 [0 - ?], potential_iss...\n",
            "7   0.998698  (rev_stop = range1 [-? - 0], potential_issue =...\n",
            "8   0.950243  (oe_constraint = range1 [-? - 0.500], deck_ris...\n",
            "9   0.950488  (rev_stop = range1 [-? - 0], deck_risk = range...\n",
            "10  0.960559  (oe_constraint = range1 [-? - 0.500], stop_aut...\n",
            "11  0.999755  (oe_constraint = range1 [-? - 0.500], rev_stop...\n",
            "12  0.960804  (stop_auto_buy = range2 [0 - ?], rev_stop = ra...\n",
            "13  0.959257  (oe_constraint = range1 [-? - 0.500], stop_aut...\n",
            "14  0.998453  (oe_constraint = range1 [-? - 0.500], rev_stop...\n",
            "15  0.959502  (stop_auto_buy = range2 [0 - ?], rev_stop = ra...\n",
            "16  0.950243  (oe_constraint = range1 [-? - 0.500], rev_stop...\n",
            "17  0.960559  (stop_auto_buy = range2 [0 - ?], oe_constraint...\n",
            "18  0.959257  (stop_auto_buy = range2 [0 - ?], oe_constraint...\n",
            "\n",
            "Association Rules:\n",
            "                                           antecedents  ... conviction\n",
            "0               (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "1             (potential_issue = range1 [-? - 0.500])  ...   0.998698\n",
            "2                    (stop_auto_buy = range2 [0 - ?])  ...   0.960804\n",
            "3             (potential_issue = range1 [-? - 0.500])  ...   0.998698\n",
            "4                        (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "5             (potential_issue = range1 [-? - 0.500])  ...        inf\n",
            "6               (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "7                   (deck_risk = range1 [-? - 0.500])  ...   0.950488\n",
            "8                        (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "9                   (deck_risk = range1 [-? - 0.500])  ...        inf\n",
            "10              (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "11                   (stop_auto_buy = range2 [0 - ?])  ...   0.960804\n",
            "12              (oe_constraint = range1 [-? - 0.500])  ...        inf\n",
            "13                       (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "14                   (stop_auto_buy = range2 [0 - ?])  ...        inf\n",
            "15                       (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "16  (oe_constraint = range1 [-? - 0.500], stop_aut...  ...   0.960559\n",
            "17  (oe_constraint = range1 [-? - 0.500], potentia...  ...   0.998453\n",
            "18  (stop_auto_buy = range2 [0 - ?], potential_iss...  ...   0.959502\n",
            "19              (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "20                   (stop_auto_buy = range2 [0 - ?])  ...   0.960804\n",
            "21            (potential_issue = range1 [-? - 0.500])  ...   0.998698\n",
            "22  (oe_constraint = range1 [-? - 0.500], rev_stop...  ...   0.999755\n",
            "23  (oe_constraint = range1 [-? - 0.500], potentia...  ...        inf\n",
            "24  (rev_stop = range1 [-? - 0], potential_issue =...  ...   0.998698\n",
            "25              (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "26                       (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "27            (potential_issue = range1 [-? - 0.500])  ...   0.998698\n",
            "28  (stop_auto_buy = range2 [0 - ?], rev_stop = ra...  ...   0.960804\n",
            "29  (stop_auto_buy = range2 [0 - ?], potential_iss...  ...        inf\n",
            "30  (rev_stop = range1 [-? - 0], potential_issue =...  ...   0.998698\n",
            "31                   (stop_auto_buy = range2 [0 - ?])  ...   0.960804\n",
            "32                       (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "33            (potential_issue = range1 [-? - 0.500])  ...   0.998698\n",
            "34  (oe_constraint = range1 [-? - 0.500], rev_stop...  ...   0.999755\n",
            "35  (oe_constraint = range1 [-? - 0.500], deck_ris...  ...        inf\n",
            "36  (rev_stop = range1 [-? - 0], deck_risk = range...  ...   0.950488\n",
            "37              (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "38                       (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "39                  (deck_risk = range1 [-? - 0.500])  ...   0.950488\n",
            "40  (oe_constraint = range1 [-? - 0.500], stop_aut...  ...        inf\n",
            "41  (stop_auto_buy = range2 [0 - ?], rev_stop = ra...  ...   0.960804\n",
            "42  (oe_constraint = range1 [-? - 0.500], rev_stop...  ...   0.999755\n",
            "43                   (stop_auto_buy = range2 [0 - ?])  ...   0.960804\n",
            "44              (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "45                       (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "46  (oe_constraint = range1 [-? - 0.500], stop_aut...  ...   0.960559\n",
            "47  (oe_constraint = range1 [-? - 0.500], stop_aut...  ...        inf\n",
            "48  (stop_auto_buy = range2 [0 - ?], potential_iss...  ...   0.959502\n",
            "49  (oe_constraint = range1 [-? - 0.500], rev_stop...  ...   0.998453\n",
            "50  (oe_constraint = range1 [-? - 0.500], stop_aut...  ...   0.960559\n",
            "51  (stop_auto_buy = range2 [0 - ?], rev_stop = ra...  ...   0.960804\n",
            "52  (stop_auto_buy = range2 [0 - ?], potential_iss...  ...   0.959502\n",
            "53  (oe_constraint = range1 [-? - 0.500], rev_stop...  ...   0.999755\n",
            "54  (oe_constraint = range1 [-? - 0.500], potentia...  ...   0.998453\n",
            "55  (rev_stop = range1 [-? - 0], potential_issue =...  ...   0.998698\n",
            "56                   (stop_auto_buy = range2 [0 - ?])  ...   0.960804\n",
            "57              (oe_constraint = range1 [-? - 0.500])  ...   0.999755\n",
            "58                       (rev_stop = range1 [-? - 0])  ...   1.000000\n",
            "59            (potential_issue = range1 [-? - 0.500])  ...   0.998698\n",
            "\n",
            "[60 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjZZGKSbsJgO"
      },
      "source": [
        "We managed to obtain very similar results, whereby when\r\n",
        "\r\n",
        "*   oe_constraint\r\n",
        "*   potential_issue\r\n",
        "*   desk_risk\r\n",
        "\r\n",
        "is **False**, the rev_stop is also **False**.\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k4PCIG5aBUv"
      },
      "source": [
        "## Clustering\r\n",
        "\r\n",
        "Clustering is an unsupervised machine learning algorithm that divide the population or data points into a number of groups such that data points in the same groups are more similar to other data points in the same group and dissimilar to the data points in other groups. It is basically a collection of objects on the basis of similarity and dissimilarity between them.\r\n",
        "\r\n",
        "The clustering algorithm we use is K-Means as it is one of the fastest clustering algorithms. We will use the Davies-Bouldin Index to measure its performance. A high Davies-Bouldin score means that the clusters are very similar to each other, whereas a low Davies-Bouldin score means that the clusters are well separated from each other. **In general, we want a low score.**\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "## RapidMiner\r\n",
        "We first run it on RapidMiner. We are only using the \"Yes\" backorder products as using the \"No\" backorder products will turn the task into a classification task. The task is repeated 5 times for 5 different number of clusters. Figure below shows the operators used in RapidMiner:\r\n",
        "![](https://drive.google.com/uc?export=view&id=1G67TbF00e4_7DxKVIBIeGwqBAOS7CN83)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGXmiP8FICCD"
      },
      "source": [
        "Next, we can run it on Python, starting with 2 clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHzg5C8DZ-Po",
        "outputId": "721518fd-8c6c-44b8-937c-b0a9fa7b1708"
      },
      "source": [
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.metrics import davies_bouldin_score\r\n",
        "\r\n",
        "# Select only backorder data\r\n",
        "bo_df = df[df['went_on_backorder'] == 1]\r\n",
        "X = bo_df.drop(columns='went_on_backorder', axis=0)\r\n",
        "\r\n",
        "# Clustering\r\n",
        "KMmodel = KMeans(n_clusters=2)\r\n",
        "KMpred = KMmodel.fit_predict(X)\r\n",
        "KMlabels = KMmodel.labels_\r\n",
        "KMbi = davies_bouldin_score(X, KMlabels)\r\n",
        "print(\"K-Means with 2 clusters\")\r\n",
        "print(\"Davies-Bouldin Index:\", KMbi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-Means with 2 clusters\n",
            "Davies-Bouldin Index: 0.4324246018578214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT9zilXAazwv"
      },
      "source": [
        "We obtained a Davies-Bouldin score of 0.432.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now we try with 4 clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9cSbp1JP8nw",
        "outputId": "707e7dec-7970-4770-b7b5-81891bd4d155"
      },
      "source": [
        "# Clustering\r\n",
        "KMmodel = KMeans(n_clusters=4)\r\n",
        "KMpred = KMmodel.fit_predict(X)\r\n",
        "KMlabels = KMmodel.labels_\r\n",
        "KMbi = davies_bouldin_score(X, KMlabels)\r\n",
        "print(\"K-Means with 4 clusters\")\r\n",
        "print(\"Davies-Bouldin Index:\", KMbi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-Means with 4 clusters\n",
            "Davies-Bouldin Index: 0.48389029593856103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkKyWetYa093"
      },
      "source": [
        "And obtained a score of 0.484\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Finally, we test with 3 clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILw-K8NUP-LA",
        "outputId": "abde037d-b6a0-426b-a5bf-10abfa2c60e9"
      },
      "source": [
        "# Clustering\r\n",
        "KMmodel = KMeans(n_clusters=3)\r\n",
        "KMpred = KMmodel.fit_predict(X)\r\n",
        "KMlabels = KMmodel.labels_\r\n",
        "KMbi = davies_bouldin_score(X, KMlabels)\r\n",
        "print(\"K-Means with 3 clusters\")\r\n",
        "print(\"Davies-Bouldin Index:\", KMbi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-Means with 3 clusters\n",
            "Davies-Bouldin Index: 0.31455921648427315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRZ1B12ZHwYj"
      },
      "source": [
        "And obtained a score of 0.315. This is the best result we have obtained so we will use this to cluster our data.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "The figure below shows the Davies-Bouldin Index for different clusters on RapidMiner and Colab. As we can see, the score on both platforms converged at k=3, which is a good sign that k=3 is the optimal number of clusters.\r\n",
        "![](https://drive.google.com/uc?export=view&id=16JS_IQezVKCyqOCI3JMJuwLuLIsuAGFR)\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Finally, using k=3, we can analyse the properties of the different clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "SB_DHEp0PEqc",
        "outputId": "d83d8463-a415-432b-8105-95294cfbd6a9"
      },
      "source": [
        "# Add cluster column\r\n",
        "KM = X.copy()\r\n",
        "KM['cluster'] = pd.Series(KMpred, index=KM.index)\r\n",
        "\r\n",
        "# Separate into different clusters\r\n",
        "cl0 = KM.loc[KM['cluster'] == 0]\r\n",
        "cl1 = KM.loc[KM['cluster'] == 1]\r\n",
        "cl2 = KM.loc[KM['cluster'] == 2]\r\n",
        "\r\n",
        "# Find out number of instances in each cluster\r\n",
        "print(\"Cluster_0: \", cl0.shape)\r\n",
        "print(\"Cluster_1: \", cl1.shape)\r\n",
        "print(\"Cluster_2: \", cl2.shape)\r\n",
        "\r\n",
        "# Aggregate the different clusters\r\n",
        "cl0_mean = cl0.agg('mean').drop('cluster')\r\n",
        "cl1_mean = cl1.agg('mean').drop('cluster')\r\n",
        "cl2_mean = cl2.agg('mean').drop('cluster')\r\n",
        "\r\n",
        "pd.concat([cl0_mean, cl1_mean, cl2_mean], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cluster_0:  (346361, 22)\n",
            "Cluster_1:  (828, 22)\n",
            "Cluster_2:  (40, 22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>national_inv</th>\n",
              "      <td>9.537295</td>\n",
              "      <td>5496.660665</td>\n",
              "      <td>-160.352666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lead_time</th>\n",
              "      <td>6.726865</td>\n",
              "      <td>5.467231</td>\n",
              "      <td>2.640487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in_transit_qty</th>\n",
              "      <td>4.172067</td>\n",
              "      <td>268.263090</td>\n",
              "      <td>3.942969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forecast_3_month</th>\n",
              "      <td>137.624462</td>\n",
              "      <td>11495.867719</td>\n",
              "      <td>66753.853709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forecast_6_month</th>\n",
              "      <td>202.867500</td>\n",
              "      <td>22109.278648</td>\n",
              "      <td>122095.135061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>forecast_9_month</th>\n",
              "      <td>268.933675</td>\n",
              "      <td>32379.571690</td>\n",
              "      <td>149564.956099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sales_1_month</th>\n",
              "      <td>32.275657</td>\n",
              "      <td>2451.704266</td>\n",
              "      <td>789.577844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sales_3_month</th>\n",
              "      <td>87.078676</td>\n",
              "      <td>9300.531564</td>\n",
              "      <td>2737.897364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sales_6_month</th>\n",
              "      <td>151.454007</td>\n",
              "      <td>17318.942791</td>\n",
              "      <td>5208.318507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sales_9_month</th>\n",
              "      <td>219.768862</td>\n",
              "      <td>24294.277592</td>\n",
              "      <td>5732.641159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min_bank</th>\n",
              "      <td>24.826702</td>\n",
              "      <td>2534.633231</td>\n",
              "      <td>755.865461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>potential_issue</th>\n",
              "      <td>0.005686</td>\n",
              "      <td>0.118768</td>\n",
              "      <td>0.116015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pieces_past_due</th>\n",
              "      <td>3.835824</td>\n",
              "      <td>465.845689</td>\n",
              "      <td>63.803605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perf_6_month_avg</th>\n",
              "      <td>0.712468</td>\n",
              "      <td>0.683012</td>\n",
              "      <td>0.876535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perf_12_month_avg</th>\n",
              "      <td>0.714702</td>\n",
              "      <td>0.729319</td>\n",
              "      <td>0.856673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>local_bo_qty</th>\n",
              "      <td>4.291423</td>\n",
              "      <td>709.182030</td>\n",
              "      <td>287.713752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deck_risk</th>\n",
              "      <td>0.087847</td>\n",
              "      <td>0.534198</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oe_constraint</th>\n",
              "      <td>0.000886</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ppap_risk</th>\n",
              "      <td>0.125307</td>\n",
              "      <td>0.308994</td>\n",
              "      <td>0.893252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stop_auto_buy</th>\n",
              "      <td>0.975329</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rev_stop</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            0             1              2\n",
              "national_inv         9.537295   5496.660665    -160.352666\n",
              "lead_time            6.726865      5.467231       2.640487\n",
              "in_transit_qty       4.172067    268.263090       3.942969\n",
              "forecast_3_month   137.624462  11495.867719   66753.853709\n",
              "forecast_6_month   202.867500  22109.278648  122095.135061\n",
              "forecast_9_month   268.933675  32379.571690  149564.956099\n",
              "sales_1_month       32.275657   2451.704266     789.577844\n",
              "sales_3_month       87.078676   9300.531564    2737.897364\n",
              "sales_6_month      151.454007  17318.942791    5208.318507\n",
              "sales_9_month      219.768862  24294.277592    5732.641159\n",
              "min_bank            24.826702   2534.633231     755.865461\n",
              "potential_issue      0.005686      0.118768       0.116015\n",
              "pieces_past_due      3.835824    465.845689      63.803605\n",
              "perf_6_month_avg     0.712468      0.683012       0.876535\n",
              "perf_12_month_avg    0.714702      0.729319       0.856673\n",
              "local_bo_qty         4.291423    709.182030     287.713752\n",
              "deck_risk            0.087847      0.534198       1.000000\n",
              "oe_constraint        0.000886      0.000000       0.000000\n",
              "ppap_risk            0.125307      0.308994       0.893252\n",
              "stop_auto_buy        0.975329      1.000000       1.000000\n",
              "rev_stop             0.000000      0.000000       0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXqslIqHsoro"
      },
      "source": [
        "We find out that:\r\n",
        "\r\n",
        "*   Most items are in the Cluster_0\r\n",
        "*   Cluster_1 and Cluster_2 are outliers\r\n",
        "*   Cluster_0 has a low inventory at an average of 9.72, and a higher sales at 32.59.\r\n",
        "*   Cluster_1 has a high inventory at 6501.40 and a lower sales at 2487.\r\n",
        "*   Cluster_2 has a negative inventory at -380.10 and a positive sales at 861.34.\r\n",
        "\r\n",
        "**Cluster 0 and Cluster 2 confirms our results earlier that, a higher sales than inventory will result in a backorder.**\r\n",
        "On the other hand, Cluster_1 has a lower sales than inventory, however there are only small a small quantity of items that are in this cluster. Cluster_1 is the outlier.\r\n",
        "\r\n",
        "---\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ysD3d0ZuUi"
      },
      "source": [
        "# **Predictive Data Mining**\r\n",
        "\r\n",
        "Predictive data mining allows us to predict events that has not happened yet. This type of data mining is done for the purpose of using business intelligence or other data to forecast or predict trends. This type of data mining can help business leaders make better decisions and can add value to the efforts of the analytics team.\r\n",
        "\r\n",
        "For this project, we are comparing Random Forest and Adaboost. Random forests are an ensemble learning method for classification. It works by constructing a multitude of Decision Trees at training time and outputting the class that is the mode of the classes.\r\n",
        "\r\n",
        "Adaboost is also an ensemble learning method, but can be used in conjunction with many other types of learning algorithms instead of just Decision Tree.\r\n",
        "\r\n",
        "Note that we do not use the forecast because they are predicted values, and we do not use min_bank because it is a 'recommended' value. We only want actual numbers for our prediction.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "### RapidMiner\r\n",
        "First, we run this on RapidMiner. Using the default max_depth=10 for both Random Forest and AdaBoost, we calculate the performance on different train-test ratios, 80:20 and 70:30. The figure below shows our operators on RapidMiner:\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=19ekMULjfMtDli8MApstGBsRMt079vgvK)\r\n",
        "\r\n",
        "The figure below shows the tabulated results:\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1sl5wHuQXs6UAgKh_It9BGlOnrtRYKFdl)\r\n",
        "\r\n",
        "We can see that, overall, Random Forest outperformed AdaBoost by as much as 10% in terms of precision.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q4rx_xpxGdO"
      },
      "source": [
        "## 30% Test Ratio\r\n",
        "\r\n",
        "We can now test in on Colab. Starting with 30% testing ratio and a max_depth=1 on Random Forest,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_CIPEvUaLTY",
        "outputId": "2dc50fcd-a1f0-4d08-8801-3a7654fb8cd0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\r\n",
        "from joblib import dump\r\n",
        "from time import perf_counter\r\n",
        "\r\n",
        "# selecting features that we want\r\n",
        "X = df.drop(columns=['went_on_backorder', 'forecast_3_month', 'forecast_6_month', 'forecast_9_month', 'perf_12_month_avg', 'sales_1_month', 'sales_3_month', 'sales_9_month', 'min_bank'], axis=0)\r\n",
        "Y = df['went_on_backorder']\r\n",
        "\r\n",
        "# test size\r\n",
        "test_size = 0.3\r\n",
        "\r\n",
        "# train test split\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\r\n",
        "print(\"Train to test ratio:\", 1-test_size, test_size)\r\n",
        "\r\n",
        "# training random forest\r\n",
        "start = perf_counter()\r\n",
        "RFmodel = RandomForestClassifier(max_depth=1)\r\n",
        "RFmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing random forest\r\n",
        "RFpred = RFmodel.predict(X_test)\r\n",
        "RFacc = round(accuracy_score(Y_test, RFpred) * 100, 2)\r\n",
        "RFprec = round(precision_score(Y_test, RFpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "RFrec = round(recall_score(Y_test, RFpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"Random Forest\", \"Accuracy\", RFacc, \"Precision:\", RFprec, \"Recall:\", RFrec)\r\n",
        "print(\"Random Forest Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train to test ratio: 0.7 0.3\n",
            "Random Forest Accuracy 79.69 Precision: 79.97 Recall: 79.69\n",
            "Random Forest Time Elapsed:  15.01725381600005  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNuu4aYxdNA7"
      },
      "source": [
        "We obtained the following results:\r\n",
        "*   Accuracy: 79.69%\r\n",
        "*   Precision: 79.97%\r\n",
        "*   Recall: 79.69%\r\n",
        "*   Time elapsed: 15 seconds\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now we use a max_depth=10 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irm2RhY6QRRH",
        "outputId": "f97cf470-50a2-459a-a01d-6debc62aa538"
      },
      "source": [
        "# training random forest\r\n",
        "start = perf_counter()\r\n",
        "RFmodel = RandomForestClassifier(max_depth=10)\r\n",
        "RFmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing random forest\r\n",
        "RFpred = RFmodel.predict(X_test)\r\n",
        "RFacc = round(accuracy_score(Y_test, RFpred) * 100, 2)\r\n",
        "RFprec = round(precision_score(Y_test, RFpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "RFrec = round(recall_score(Y_test, RFpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"Random Forest\", \"Accuracy\", RFacc, \"Precision:\", RFprec, \"Recall:\", RFrec)\r\n",
        "print(\"Random Forest Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy 90.64 Precision: 90.77 Recall: 90.64\n",
            "Random Forest Time Elapsed:  74.78256261299993  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uxg4mXNdNy7"
      },
      "source": [
        "And obtained the following results:\r\n",
        "*   Accuracy: 90.64%\r\n",
        "*   Precision: 90.77%\r\n",
        "*   Recall: 90.64%\r\n",
        "*   Time elapsed: 75 seconds\r\n",
        "\r\n",
        "We can see that by increase the number of max_depth, we greatly increased the time it took to train the model.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "We do the same thing again with max_depth=25 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F88ncsKjPIIE",
        "outputId": "58a8d27a-5ccf-431a-8eef-1d07f0109e13"
      },
      "source": [
        "# training random forest\r\n",
        "start = perf_counter()\r\n",
        "RFmodel = RandomForestClassifier(max_depth=25)\r\n",
        "RFmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing random forest\r\n",
        "RFpred = RFmodel.predict(X_test)\r\n",
        "RFacc = round(accuracy_score(Y_test, RFpred) * 100, 2)\r\n",
        "RFprec = round(precision_score(Y_test, RFpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "RFrec = round(recall_score(Y_test, RFpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"Random Forest\", \"Accuracy\", RFacc, \"Precision:\", RFprec, \"Recall:\", RFrec)\r\n",
        "print(\"Random Forest Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy 97.76 Precision: 97.77 Recall: 97.76\n",
            "Random Forest Time Elapsed:  112.1124660160001  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtmPP1h-dOtr"
      },
      "source": [
        "And obtained the following results:\r\n",
        "*   Accuracy: 97.76%\r\n",
        "*   Precision: 97.77%\r\n",
        "*   Recall: 97.76%\r\n",
        "*   Time elapsed: 112 seconds\r\n",
        "\r\n",
        "This is the best result with Random Forest so far. However, we can not know if we are overfitting until we test our model on the data product\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now, we can train our Adaboost model. First we use Naive Bayes, particularly the Gaussian Naive Bayes, as the base estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql4SqzN1QY8Q",
        "outputId": "f09ece92-20b6-4e7d-b6cc-d04482697294"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "\r\n",
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "ABmodel = AdaBoostClassifier(base_estimator=GaussianNB())\r\n",
        "ABmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = ABmodel.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 65.98 Precision: 68.65 Recall: 65.98\n",
            "AdaBoost Time Elapsed:  24.231937038999945  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acoFrIszdP9L"
      },
      "source": [
        " We obtained the following results:\r\n",
        "*   Accuracy: 65.98%\r\n",
        "*   Precision: 68.65%\r\n",
        "*   Recall: 65.98%\r\n",
        "*   Time elapsed: 24 seconds\r\n",
        "\r\n",
        "This is not a good result, so we will not use this model\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Next, we try the ExtraTreeClassifier as the base estimator. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "123WzaaKQZCl",
        "outputId": "d449591b-092b-4e54-f940-c18c4e888fec"
      },
      "source": [
        "from sklearn.tree import ExtraTreeClassifier\r\n",
        "\r\n",
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "ABmodel = AdaBoostClassifier(base_estimator=ExtraTreeClassifier())\r\n",
        "ABmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = ABmodel.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 96.89 Precision: 96.89 Recall: 96.89\n",
            "AdaBoost Time Elapsed:  44.81217424199997  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWjeyP17dUH7"
      },
      "source": [
        "We obtained the following results:\r\n",
        "*   Accuracy: 96.89%\r\n",
        "*   Precision: 96.89%\r\n",
        "*   Recall: 96.89%\r\n",
        "*   Time elapsed: 44 seconds\r\n",
        "\r\n",
        "This is a good result, but we can do better.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now we can test the default base estimator, which is the Decision Tree if no parameters are given. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8Z83tPh7H4m",
        "outputId": "1a6d2260-8076-4394-cb28-23b930e33e27"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "\r\n",
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "ABmodel = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\r\n",
        "ABmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = ABmodel.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 98.43 Precision: 98.43 Recall: 98.43\n",
            "AdaBoost Time Elapsed:  214.69023468800003  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqTwiSKB8PeQ"
      },
      "source": [
        "We obtained the following results:\r\n",
        "*   Accuracy: 98.43%\r\n",
        "*   Precision: 98.43%\r\n",
        "*   Recall: 98.43%\r\n",
        "*   Time elapsed: 215 seconds\r\n",
        "\r\n",
        "The accuracy, precision, and recall are very high, however it took much longer to train. \r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now that we have determined Decision Tree is a good base estimator, we can try it with max_depth=1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWtxBNUgkcK8",
        "outputId": "fcaa054c-f6a9-4e52-9079-a82640343231"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "\r\n",
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "ABmodel = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1))\r\n",
        "ABmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = ABmodel.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 87.32 Precision: 87.35 Recall: 87.32\n",
            "AdaBoost Time Elapsed:  30.614752263000014  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qATmAsIs8SCO"
      },
      "source": [
        "We obtained the following results:\r\n",
        "*   Accuracy: 87.32%\r\n",
        "*   Precision: 87.35%\r\n",
        "*   Recall: 87.32%\r\n",
        "*   Time elapsed: 31 seconds\r\n",
        "\r\n",
        "The time elapsed is much lower, but the performance is still relatively good.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now we try with max_depth=25 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaueeWjXPGoD",
        "outputId": "336223d4-facf-47ee-cdda-46abca222a9a"
      },
      "source": [
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "ABmodel = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=25))\r\n",
        "ABmodel.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = ABmodel.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 98.7 Precision: 98.7 Recall: 98.7\n",
            "AdaBoost Time Elapsed:  194.90734541999996  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_S-Qa9IdVpz"
      },
      "source": [
        "And obtained the following results:\r\n",
        "*   Accuracy: 98.70%\r\n",
        "*   Precision: 98.70%\r\n",
        "*   Recall: 98.70%\r\n",
        "*   Time elapsed: 195 seconds\r\n",
        "\r\n",
        "This is the longest time elapsed so far, but also the best performance in terms of accuracy, precision, and recall. Again, we will not know if the model is overfitting the data until we test it on our data product.\r\n",
        "\r\n",
        "---\r\n",
        "## 20% Test Ratio\r\n",
        "\r\n",
        "Now, we can try to run the same process with 20% testing ratio instead. Starting with Random Forest with max_depth=1, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8RJHy1HSRtG",
        "outputId": "d77e5498-cdf7-4429-b372-02bab1b3e309"
      },
      "source": [
        "# test size\r\n",
        "test_size = 0.2\r\n",
        "\r\n",
        "# train test split\r\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=42)\r\n",
        "print(\"Train to test ratio:\", 1-test_size, test_size)\r\n",
        "\r\n",
        "# training random forest\r\n",
        "start = perf_counter()\r\n",
        "RF_1 = RandomForestClassifier(max_depth=1)\r\n",
        "RF_1.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing random forest\r\n",
        "RFpred = RF_1.predict(X_test)\r\n",
        "RFacc = round(accuracy_score(Y_test, RFpred) * 100, 2)\r\n",
        "RFprec = round(precision_score(Y_test, RFpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "RFrec = round(recall_score(Y_test, RFpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"Random Forest\", \"Accuracy\", RFacc, \"Precision:\", RFprec, \"Recall:\", RFrec)\r\n",
        "print(\"Random Forest Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train to test ratio: 0.8 0.2\n",
            "Random Forest Accuracy 78.69 Precision: 78.83 Recall: 78.69\n",
            "Random Forest Time Elapsed:  15.100225382999952  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IR_t9eFD4cJ"
      },
      "source": [
        "we obtained the results:\r\n",
        "*   Accuracy: 78.69%\r\n",
        "*   Precision: 78.83%\r\n",
        "*   Recall: 78.69%\r\n",
        "*   Time elapsed: 15 seconds\r\n",
        "\r\n",
        "The time elapsed is very low and the performance is relatively high.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "We do the same thing but with max_depth=10. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vljTvrkjU-Nk",
        "outputId": "6f13ee80-4cfb-45ce-ad5e-a6ef57cc56ce"
      },
      "source": [
        "# training random forest\r\n",
        "start = perf_counter()\r\n",
        "RF_10 = RandomForestClassifier(max_depth=10)\r\n",
        "RF_10.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing random forest\r\n",
        "RFpred = RF_10.predict(X_test)\r\n",
        "RFacc = round(accuracy_score(Y_test, RFpred) * 100, 2)\r\n",
        "RFprec = round(precision_score(Y_test, RFpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "RFrec = round(recall_score(Y_test, RFpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"Random Forest\", \"Accuracy\", RFacc, \"Precision:\", RFprec, \"Recall:\", RFrec)\r\n",
        "print(\"Random Forest Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy 90.76 Precision: 90.9 Recall: 90.76\n",
            "Random Forest Time Elapsed:  74.43826018799996  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv-yYChftVjD"
      },
      "source": [
        "We obtained the results:\r\n",
        "*   Accuracy: 90.76%\r\n",
        "*   Precision: 90.90%\r\n",
        "*   Recall: 90.76%\r\n",
        "*   Time elapsed: 74 seconds\r\n",
        "\r\n",
        "This is a very good result.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now let's try max_depth=25\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmk3tJ6U_VMQ",
        "outputId": "d8f82485-5f56-4e59-d84b-47e86b20d87d"
      },
      "source": [
        "# training random forest\r\n",
        "start = perf_counter()\r\n",
        "RF_25 = RandomForestClassifier(max_depth=25)\r\n",
        "RF_25.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing random forest\r\n",
        "RFpred = RF_25.predict(X_test)\r\n",
        "RFacc = round(accuracy_score(Y_test, RFpred) * 100, 2)\r\n",
        "RFprec = round(precision_score(Y_test, RFpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "RFrec = round(recall_score(Y_test, RFpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"Random Forest\", \"Accuracy\", RFacc, \"Precision:\", RFprec, \"Recall:\", RFrec)\r\n",
        "print(\"Random Forest Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy 97.86 Precision: 97.87 Recall: 97.86\n",
            "Random Forest Time Elapsed:  114.00814012799992  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYZXVtNLdYbs"
      },
      "source": [
        "We get the results:\r\n",
        "*   Accuracy: 97.86%\r\n",
        "*   Precision: 97.87%\r\n",
        "*   Recall: 97.86%\r\n",
        "*   Time elapsed: 114 seconds\r\n",
        "\r\n",
        "This is the best performance for our Random Forest.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "We do the same thing for Adaboost, starting with max_depth=1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFD9WIhj_aEX",
        "outputId": "b69b8e25-25f1-46ed-fa3e-266d284a48d6"
      },
      "source": [
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "AB_1 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1))\r\n",
        "AB_1.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = AB_1.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 87.38 Precision: 87.41 Recall: 87.38\n",
            "AdaBoost Time Elapsed:  31.59044422099987  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyWCwgahtsrw"
      },
      "source": [
        "We obtained the results:\r\n",
        "*   Accuracy: 87.38%\r\n",
        "*   Precision: 87.41%\r\n",
        "*   Recall: 87.38%\r\n",
        "*   Time elapsed: 32 seconds\r\n",
        "\r\n",
        "We see that when the max_depth are the same, Adaboost outperformed Random Forest, contrary to our results from RapidMiner. Adaboost took twice as long as Random Forest to train.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Now we can try max_depth=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EieG4NnsU7yl",
        "outputId": "d7948273-8bb1-4021-84dd-dbe9734a23aa"
      },
      "source": [
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "AB_10 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=10))\r\n",
        "AB_10.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = AB_10.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 98.8 Precision: 98.8 Recall: 98.8\n",
            "AdaBoost Time Elapsed:  218.75830530500002  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q32xbq9NEWhp"
      },
      "source": [
        "We obtained the results:\r\n",
        "*   Accuracy: 98.80%\r\n",
        "*   Precision: 98.80%\r\n",
        "*   Recall: 98.80%\r\n",
        "*   Time elapsed: 219 seconds\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Finally, we try max_depth=25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEd5ZX__SQgH",
        "outputId": "8e552822-49e2-45f0-e4e4-41b959813acb"
      },
      "source": [
        "# training adaboost\r\n",
        "start = perf_counter()\r\n",
        "AB_25 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=25))\r\n",
        "AB_25.fit(X_train, Y_train)\r\n",
        "\r\n",
        "# testing adaboost\r\n",
        "ABpred = AB_25.predict(X_test)\r\n",
        "ABacc = round(accuracy_score(Y_test, ABpred) * 100, 2)\r\n",
        "ABprec = round(precision_score(Y_test, ABpred, average='weighted', zero_division=0) * 100, 2)\r\n",
        "ABrec = round(recall_score(Y_test, ABpred, average='weighted') * 100, 2)\r\n",
        "time_elapsed = perf_counter() - start\r\n",
        "print(\"AdaBoost\", \"Accuracy:\", ABacc, \"Precision:\", ABprec, \"Recall:\", ABrec)\r\n",
        "print(\"AdaBoost Time Elapsed: \", time_elapsed, \" seconds.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoost Accuracy: 98.81 Precision: 98.81 Recall: 98.81\n",
            "AdaBoost Time Elapsed:  244.1962600600002  seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06Gm7iHGdZNz"
      },
      "source": [
        " We obtained the results:\r\n",
        "*   Accuracy: 98.81%\r\n",
        "*   Precision: 98.81%\r\n",
        "*   Recall: 98.81%\r\n",
        "*   Time elapsed: 244 seconds\r\n",
        "\r\n",
        "Again, we see a higher slightly performance compared to Random Forest, and again the training took twice as long.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "We save both the Random Forest and the Adaboost forest, for max_depth=1, max_depth=10 and max_depth=25. This is because we want to test if any of these models are overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6pZpCE6SX99",
        "outputId": "b533c664-03bf-4218-925e-415e9bfdbe1c"
      },
      "source": [
        "# save model\r\n",
        "dump(RF_1, 'RandomForest_1.joblib')\r\n",
        "dump(RF_10, 'RandomForest_10.joblib')\r\n",
        "dump(RF_25, 'RandomForest_25.joblib')\r\n",
        "\r\n",
        "# save model\r\n",
        "dump(AB_1, 'Adaboost_1.joblib')\r\n",
        "dump(AB_10, 'Adaboost_10.joblib')\r\n",
        "dump(AB_25, 'Adaboost_25.joblib')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adaboost_25.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVlZjD37Zuch"
      },
      "source": [
        "---\r\n",
        "# **Results and Analysis**\r\n",
        "---\r\n",
        "\r\n",
        "## Exploratory Data Analysis\r\n",
        "From our exploratory data analysis, **we can see that there is indeed a correlation between national inventory, sales performance, and backorder**. Generally, when the sales performance exceeds the national inventory, the product becomes a backorder. Another thing we have learned from the data analysis is that, when the sales performance exceeds the forecasted sales, then there is a high probability that the product will also go on backorder.\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "## Association Rules\r\n",
        "With association rules, we can see the relationship between the attributes. The categorical attributes (oe_constraint, desk_risk, rev_stop) frequently go together. **When oe_constraint is false, then there is a high likelihood that rev_stop is also false, and vice versa.**\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "## Clustering\r\n",
        "With clustering, we are able to cluster similar instances together. Within the \"Yes\" backorder products, we see that cluster 0 is the majority cluster, whereas cluster 1 and cluster 2 can be considered as an outlier. **Cluster 0 is low in sales and inventory, cluster 1 is high in both sales and inventory, and cluster 2 is in between the two.**\r\n",
        "\r\n",
        "For cluster 0 and cluster 2, we see that the average sales do exceed the average inventory, which confirms our hypothesis. Cluster 1 contradicts our hypothesis, but it can be considered an outlier to the data.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "## Predictive Data Mining\r\n",
        "After comparing 2 classification algorithms, we find that, in general, **Adaboost has the higher accuracy, precision, and recall than Random Forest**, when max_depth are the same. \r\n",
        "\r\n",
        "The result here on Colab is different to our results on RapidMiner. On RapidMiner, the performance of Random Forest is higher than Adaboost. I'm not certain why, and I can only hypothesize that it is due to a different implementation of the algorithms.\r\n",
        "\r\n",
        "Here is the tabulated results:\r\n",
        "\r\n",
        "![](https://drive.google.com/uc?export=view&id=1c_dKXSM4crxS4BB-Wej9oz0_UmBXwPSG)\r\n",
        "\r\n",
        "If we look at the file sizes, Adaboost_1, Adaboost_10, Adaboost_25 have file sizes 31.1KB, 2.85MB, and 17.5MB respectively.\r\n",
        "\r\n",
        "On the other hand, RandomForest_1, RandomForest_10, and RandomForest_25 have file sizes 60KB, 6.84MB, and 156MB respectively.\r\n",
        "\r\n",
        "As for time taken to train the model, Adaboost_1, Adaboost_10, Adaboost_25 took 32, 219, and 244 seconds respectively.\r\n",
        "\r\n",
        "RandomForest_1, RandomForest_10, and RandomForest_25 took 15, 74, 114 seconds respectively.\r\n",
        "\r\n",
        "**Adaboost takes twice as long as Random Forest to train.**\r\n",
        "\r\n",
        "However, we won't know if any of these models are overfitting until we test it in the Data product."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtkiT7IhZ4Pp"
      },
      "source": [
        "# **Data Product**\r\n",
        "\r\n",
        "The data product is built on streamlit because it allows us to rapidly prototype a data product without much coding. Our data product allows the user to manipulate the variables and predict if they will be a backorder or not. We will use these features to predict the backorder:\r\n",
        "\r\n",
        "*  national_inv\r\n",
        "*  lead_time\r\n",
        "*  In_transit_qty\r\n",
        "*  sales_6_month\r\n",
        "*  perf_6_months_avg\r\n",
        "*  potential_issue\r\n",
        "*  pieces_past_due\r\n",
        "*  local_bo_qty\r\n",
        "*  deck_risk\r\n",
        "*  oe_constraint\r\n",
        "*  ppap_risk\r\n",
        "*  stop_auto_buy\r\n",
        "*  rev_stop\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an5SC8dUcE-f",
        "outputId": "cf7d4bfa-84b4-40dc-b835-1376a4a8d6f3"
      },
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from joblib import load\n",
        "from PIL import Image\n",
        "\n",
        "DATA_PATH = 'data.csv'\n",
        "\n",
        "@st.cache\n",
        "def load_data(path):\n",
        "    data = pd.read_csv(path)\n",
        "    lowercase = lambda x: str(x).lower()\n",
        "    data.rename(lowercase, axis='columns', inplace=True)\n",
        "    return data\n",
        "\n",
        "data_load_state = st.text('Loading data...')\n",
        "df = load_data(DATA_PATH)\n",
        "data_load_state.text(\"Done loading data!\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    @st.cache\n",
        "    def agg_data(df, mode):\n",
        "        dat = df.agg([mode])\n",
        "        return dat\n",
        "\n",
        "    data_agg_state = st.text('Aggregating data...')\n",
        "    dfMin = agg_data(df, 'min')\n",
        "    dfMax = agg_data(df, 'max')\n",
        "    dfMedian = agg_data(df, 'median')\n",
        "    dfMode = agg_data(df, 'mode')\n",
        "    data_agg_state.text(\"Done aggregating data!\")\n",
        "\n",
        "    st.title('Product Backorder')\n",
        "    st.sidebar.title(\"Features\")\n",
        "\n",
        "    quant_parameter_list = ['national_inv',\n",
        "                    'lead_time',\n",
        "                    'in_transit_qty',\n",
        "                    'sales_1_month',\n",
        "                    'pieces_past_due',\n",
        "                    'perf_6_month_avg',\n",
        "                    'local_bo_qty']\n",
        "\n",
        "    qual_parameter_list = ['potential_issue',\n",
        "                        'deck_risk',\n",
        "                        'oe_constraint',\n",
        "                        'ppap_risk',\n",
        "                        'stop_auto_buy',\n",
        "                        'rev_stop']\n",
        "\n",
        "    parameter_input_values=[]\n",
        "    values=[]\n",
        "    \n",
        "    model_select = st.selectbox(label='Select Classification Model', options=(('Adaboost_1', 'Adaboost_10','Adaboost_25', 'RandomForest_1', 'RandomForest_10', 'RandomForest_25')))\n",
        "\n",
        "    for parameter in quant_parameter_list:\n",
        "      values = st.sidebar.slider(label=parameter, key=parameter, value=float(dfMedian[parameter]), min_value=float(dfMin[parameter]), max_value=float(dfMax[parameter]), step=0.1)\n",
        "      parameter_input_values.append(values)\n",
        "\n",
        "    for parameter in qual_parameter_list:\n",
        "        ind = dfMode[parameter].iloc[0]\n",
        "        values = st.sidebar.selectbox(label=parameter, key=parameter, index=int(ind), options=('Yes', 'No'))\n",
        "        val = 1 if values == 'Yes' else 0\n",
        "        parameter_input_values.append(val)\n",
        "\n",
        "    parameter_list = quant_parameter_list + qual_parameter_list\n",
        "    input_variables=pd.DataFrame([parameter_input_values],columns=parameter_list)\n",
        "    st.write('\\n\\n')\n",
        "\n",
        "    if (model_select == \"Adaboost_1\"):\n",
        "      model = load('Adaboost_1.joblib')\n",
        "    elif (model_select == \"Adaboost_10\"):\n",
        "      model = load('Adaboost_10.joblib')\n",
        "    elif (model_select == \"Adaboost_25\"):\n",
        "      model = load('Adaboost_25.joblib')\n",
        "    elif (model_select == \"RandomForest_1\"):\n",
        "      model = load('RandomForest_1.joblib')\n",
        "    elif (model_select == \"RandomForest_10\"):\n",
        "      model = load('RandomForest_10.joblib')\n",
        "    elif (model_select == \"RandomForest_25\"):\n",
        "      model = load('RandomForest_25.joblib')\n",
        "    else:\n",
        "      model = load('Adaboost_1.joblib')\n",
        "\n",
        "    if st.button(\"Will the product be a backorder?\"):\n",
        "        prediction = model.predict(input_variables)\n",
        "        pred = 'No' if prediction == 0 else 'Yes'\n",
        "        st.text(pred)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnxFCNWvdnOj"
      },
      "source": [
        "We install ngrok so we can run streamlit on Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXprJQcTKnJB",
        "outputId": "9af1b85d-4af1-4f1f-8481-fce829e281f6"
      },
      "source": [
        "!pip -q install streamlit\r\n",
        "!pip -q install pyngrok\r\n",
        "\r\n",
        "# Setup a tunnel to the streamlit port 8501\r\n",
        "from pyngrok import ngrok\r\n",
        "public_url = ngrok.connect(port='8501')\r\n",
        "public_url"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.5MB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.6MB 59.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 60.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 52.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 4.6MB/s \n",
            "\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.4.3 which is incompatible.\u001b[0m\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://234ee057f6da.ngrok.io\" -> \"http://localhost:80\">"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUjWeMtEwBsg",
        "outputId": "8c113ad1-2dbf-4ba6-b313-d8c21982e45d"
      },
      "source": [
        "!streamlit run --server.port 80 app.py & >/dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:80\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.231.250.250:80\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay9efz5KdvnC"
      },
      "source": [
        "We can now terminate streamlit and ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TumXEnd6LkK-",
        "outputId": "e280b161-975f-478f-ee74-2f897380e70f"
      },
      "source": [
        "!pgrep streamlit\r\n",
        "ngrok.kill()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNzQ9zqYZ5iJ"
      },
      "source": [
        "# **Conclusion**\n",
        "\n",
        "We can test our model in our data product. By logical deduction and also confirmed by our data analysis earlier on, sales that exceed the national inventory will go on a backorder, and vice versa.\n",
        "\n",
        "So, first we test each model with **national_inv=100000 and sales=1**. The expected output is \"No.\" These are the results obtained:\n",
        "\n",
        "*   **Adaboost_1**: No\n",
        "*   **Adaboost_10**: No\n",
        "*   **Adaboost_25**: No\n",
        "*   **RandomForest_1**: *Yes*\n",
        "*   **RandomForest_10**: No\n",
        "*   **RandomForest_25** : No\n",
        "\n",
        "We can see that the Random Forest model with max_depth=10 is misclassifying our product.\n",
        "\n",
        "Next, we test each model with **national_inv=100 and sales=100000**. The expected output is \"Yes.\" These are the results obtained:\n",
        "\n",
        "*   **Adaboost_1**: Yes\n",
        "*   **Adaboost_10**: Yes\n",
        "*   **Adaboost_25**: Yes\n",
        "\n",
        "*   **RandomForest_1**: Yes\n",
        "*   **RandomForest_10**: Yes\n",
        "*   **RandomForest_25** : *No*\n",
        "\n",
        "\n",
        "Here is the results in tabular form:\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1efOixdGeKGp70hwKrwku_9X0N2J-bShk)\n",
        "\n",
        "We can see that **all 3 of the Adaboost models got both test cases correct**. On the other hand, for Random Forest, **only RandomForest_10 got both cases correct**.\n",
        "\n",
        "Hence, we can conclude that for this dataset, in terms of accuracy and file sizes, Adaboost is the superior model to Random Forest. However, there is a trade-off, and that is the training time. **Adaboost takes twice as long as Random Forest to train.**\n",
        "\n",
        "Since there is not much difference between Adaboost_10 and Adaboost_25 in terms of accuracy, so we can assume that there is diminishing returns after max_depth=10. Thus, **Adaboost_10 is actually the better model out of the two**.\n",
        "\n",
        "We should also keep in mind that **accuracy alone is not enough to tell the effectiveness of a model**, and there are many factors that we should consider."
      ]
    }
  ]
}